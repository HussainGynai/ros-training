<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<title>Week 6</title>
<meta name="author" content="(Sahit Chintalapudi, Jason Gibson, Andrew Tuttle)"/>
<style type="text/css">
.underline { text-decoration: underline; }
</style>
<link rel="stylesheet" href="https://revealjs.com/css/reveal.css"/>

<link rel="stylesheet" href="https://revealjs.com/css/theme/white.css" id="theme"/>


<!-- If the query includes 'print-pdf', include the PDF print sheet -->
<script>
    if( window.location.search.match( /print-pdf/gi ) ) {
        var link = document.createElement( 'link' );
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = 'https://revealjs.com/css/print/pdf.css';
        document.getElementsByTagName( 'head' )[0].appendChild( link );
    }
</script>
</head>
<body>
<div class="reveal">
<div class="slides">
<section id="sec-title-slide"><h1 class="title">Week 6</h1>
</section>

<section id="slide-org5e7acf7">
<h2 id="org5e7acf7">What are we doing today</h2>
<ul>
<li>Cameras</li>
<li>OpenCV</li>
<li>Tensorflow</li>
<li>Deep Learning for Semantic Segmentation</li>

</ul>

</section>
<section id="slide-org9ba1f33">
<h2 id="org9ba1f33">Cameras</h2>
<ul>
<li>An image is a collection of pixels</li>

</ul>
</section>
<section id="slide-orgc4249ed">
<h3 id="orgc4249ed">Stereo</h3>
<ul>
<li>Can calculate the distances to things
<ul>
<li>Finds the same features on the frames</li>
<li>known distance in between cameras</li>

</ul></li>
<li>Sensitive to amount of features</li>

</ul>

<div class="figure">
<p><img src="https://i2.wp.com/scorpion.tordivel.no/images/3D-Lens-Calculator-Sketch.png" alt="3D-Lens-Calculator-Sketch.png" />
</p>
</div>
</section>
<section id="slide-org7c536de">
<h2 id="org7c536de">Computer Vision</h2>
<ul>
<li>We have the knowledge in C++ to describe the logic we might want a robot to
have. But we need to be able to make sense of what the robot sees and
classify it before we can act on this logic.</li>
<li>Cue OpenCV, an open source computer vision library with bindings for C++
(and a few other languages)</li>
<li>I guess our ability to see has been ++'d</li>

</ul>

</section>
<section id="slide-orgf0a68c7">
<h2 id="orgf0a68c7">OpenCV</h2>
<ul>
<li>Industrial standard for image processing</li>

</ul>

<div class="figure">
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/3/32/OpenCV_Logo_with_text_svg_version.svg/1200px-OpenCV_Logo_with_text_svg_version.svg.png" alt="1200px-OpenCV_Logo_with_text_svg_version.svg.png" width="30%" />
</p>
</div>
</section>
<section id="slide-org2991587">
<h2 id="org2991587">What does an Image look like to your computer?</h2>
<ul>
<li>OpenCV stores images in an object called a <i>Mat</i></li>
<li>A Mat is an array with rows and columns. Each element
of the Mat is a pixel in the image and its location in the Mat corresponds
to its location in the image</li>
<li>Computers have no concept of "2d", so Images in memory are <i>continuous</i>.
This means each row of the image is appended onto the end of the last. To
iterate through a Mat you just get a pointer to the beginning of the first
row and keep track of your row number by how far you've traversed.</li>

</ul>
</section>
<section id="slide-orga4b093f">
<h2 id="orga4b093f">Color Types</h2>
<ul>
<li>There are many different formats for an image
<ul>
<li>Grey scale</li>
<li>RGB</li>
<li>HSV</li>

</ul></li>

</ul>
</section>
<section id="slide-orgbb0da6d">
<h3 id="orgbb0da6d">Grey scale</h3>
<ul>
<li>An image where each pixel is only white to black</li>
<li>Range [0-255]
<ul>
<li>255 is white</li>
<li>0 is black</li>

</ul></li>

</ul>
</section>
<section id="slide-orge5072bd">
<h3 id="orge5072bd">Color Images</h3>
<ul>
<li>Color images don't embed the color of a pixel in one element. Often, you'll
find each pixel represented in BGR (Blue component, Green Component, Red
Component) form. So now, each row of a color image is 3 times as long as a
row of a black and white image.</li>
<li><img src="https://i.imgur.com/QlokNTv.png" alt="QlokNTv.png" /></li>
<li>Images don't have to be stored in just BGR format!</li>

</ul>

</section>
<section id="slide-org613472d">
<h3 id="org613472d">HSV Images</h3>
<ul>
<li>Each Pixel in a color image has a hue, a saturation, and a luminosity.</li>
<li>Even though our cameras read in images with RGB, converting them to HSV is
easy with OpenCV</li>

</ul>

<div class="figure">
<p><img src="https://image.slidesharecdn.com/01presentationhuehistograms-150707215651-lva1-app6892/95/about-perception-and-hue-histograms-in-hsv-space-5-638.jpg" alt="about-perception-and-hue-histograms-in-hsv-space-5-638.jpg" />
</p>
</div>
</section>
<section id="slide-org6a4cc9f">
<h4 id="org6a4cc9f">HSV explained</h4>
<ul>
<li>Hue
<ul>
<li>The actual color</li>

</ul></li>
<li>Saturation
<ul>
<li>Indicates the amount of grey</li>

</ul></li>
<li>Luminosity
<ul>
<li>How dark the color is</li>

</ul></li>

</ul>

<div class="figure">
<p><img src="https://www.nmt.edu/tcc/help/pubs/colortheory/img/cone.png" alt="cone.png" width="30%" />
</p>
</div>

</section>
<section id="slide-org900c976">
<h4 id="org900c976">Why do we use HSV</h4>
<ul>
<li>HSV encodes image data in a way that is resistant to changes in color</li>
<li>To put it another way, on a sunny day an image will contain more red, more
blue, and more green than on a cloudy day. All three channels are affected.</li>
<li>On a sunny day, the saturation channel will be largely effected, but we can
expect hue to remain mainly stable. This makes it easier to do searches for
colors in the HSV space.</li>

</ul>

</section>
<section id="slide-orgff8de06">
<h2 id="orgff8de06">Finding the blue in an image</h2>
<p>
<a href="https://github.com/RoboJackets/ros-training/blob/master/code/week6/src/findBlue.cpp">https://github.com/RoboJackets/ros-training/blob/master/code/week6/src/findBlue.cpp</a>
</p>

</section>
<section id="slide-org99dca55">
<h2 id="org99dca55">Tensorflow</h2>
<ul>
<li>Sometimes, CV problems present themselves in such a way that Deep Learning becomes the best solution.</li>
<li>Tensorflow is a library containing machine learning algorithms.</li>
<li>We use it to provide an implementation of a neural network to perform semantic segmentation for line detection</li>

</ul>

</section>
<section id="slide-orgca51153">
<h2 id="orgca51153">Semantic Segmentation</h2>
<ul>
<li>Semantic Segmentation is the art of grouping pixels in an image into clusters that share a meaning.</li>
<li>In our use case, we classify pixels as "Not a line" or "Is a line"</li>
<li>To do this, we utilize something called a Convolutional Neural Network, or CNN</li>

</ul>

</section>
<section id="slide-orgc5db3c4">
<h2 id="orgc5db3c4">What is Convolving?</h2>
<ul>
<li>Convolving refers to the procedural application of a kernel to an image.</li>

</ul>

</section>
<section id="slide-orgf7283a1">
<h2 id="orgf7283a1">Kernels</h2>
<ul>
<li>A kernel is a square matrix</li>
<li>Each pixel value in a region of the image is multiplied by its corresponding element in the matrix, then summed for a result.</li>
<li>can be used for edge detection, reducing noise, feature extraction, etc</li>

</ul>
</section>
<section id="slide-org9343ecc">
<h3 id="org9343ecc">Identity</h3>
<ul>
<li>Returns the original image</li>

</ul>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<tbody>
<tr>
<td class="org-right">0</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
</tr>

<tr>
<td class="org-right">0</td>
<td class="org-right">1</td>
<td class="org-right">0</td>
</tr>

<tr>
<td class="org-right">0</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
</tr>
</tbody>
</table>

<div class="figure">
<p><img src="https://i.imgur.com/YWH6NPC.png" alt="YWH6NPC.png" />
</p>
</div>
</section>
<section id="slide-orgb29acb9">
<h3 id="orgb29acb9">Blur</h3>
<ul>
<li>used to reduce noise</li>
<li>replaces the center pixel with the average of all of it's neighbors.</li>

</ul>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<tbody>
<tr>
<td class="org-left">1/9</td>
<td class="org-left">1/9</td>
<td class="org-left">1/9</td>
</tr>

<tr>
<td class="org-left">1/9</td>
<td class="org-left">1/9</td>
<td class="org-left">1/9</td>
</tr>

<tr>
<td class="org-left">1/9</td>
<td class="org-left">1/9</td>
<td class="org-left">1/9</td>
</tr>
</tbody>
</table>
<p>
<img src="https://i.imgur.com/ogsHVT9.png" alt="ogsHVT9.png" />i
</p>
</section>
<section id="slide-orgfdc291c">
<h4 id="orgfdc291c">Right Sobel</h4>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<tbody>
<tr>
<td class="org-right">-1</td>
<td class="org-right">0</td>
<td class="org-right">1</td>
</tr>

<tr>
<td class="org-right">-2</td>
<td class="org-right">0</td>
<td class="org-right">2</td>
</tr>

<tr>
<td class="org-right">-1</td>
<td class="org-right">0</td>
<td class="org-right">1</td>
</tr>
</tbody>
</table>

<div class="figure">
<p><img src="https://i.imgur.com/n70YDco.png" alt="n70YDco.png" />
</p>
</div>
</section>
<section id="slide-org8424c31">
<h4 id="org8424c31">Top Sobel</h4>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<tbody>
<tr>
<td class="org-right">1</td>
<td class="org-right">2</td>
<td class="org-right">1</td>
</tr>

<tr>
<td class="org-right">0</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
</tr>

<tr>
<td class="org-right">-1</td>
<td class="org-right">-2</td>
<td class="org-right">-1</td>
</tr>
</tbody>
</table>

<div class="figure">
<p><img src="https://i.imgur.com/0ag5YRp.png" alt="0ag5YRp.png" />
</p>
</div>
</section>
<section id="slide-org42787cf">
<h4 id="org42787cf">Combination</h4>

<div class="figure">
<p><img src="https://i.imgur.com/zOUwHgY.png" alt="zOUwHgY.png" />
</p>
</div>

</section>
<section id="slide-orgdfb55a0">
<h2 id="orgdfb55a0">Back to CNN</h2>
<ul>
<li>These kernels are used to generate feature maps, which are then subjected to certain preprocessing steps and fed into a neural network as input, which then classifies each pixel as line or not-line.</li>
<li>To train our network, we manually labelled many images from past competitions and testing runs, which allows our network to preform well for our use cases.</li>
<li>For the more curious amoung you, here is a beginner's guide to CNNs that goes into more detail: <a href="https://adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks/">CNN Guide</a></li>

</ul>

</section>
<section id="slide-orgb4bb8d9">
<h2 id="orgb4bb8d9">I bet you all have wondered why I have gathered you here today.</h2>
<ul>
<li>As many of you might have noticed, we are in the shop rather than on campus.</li>
<li>In addition, many of you might have noticed our poor documentation habits.</li>
<li>We are going to be walking you (and us) through different parts of the codebase, explaining and documenting things as we go to help you get onboarded and clean up some shoddy code.</li>
<li>Welcome to the Shop!</li>

</ul>
</section>
</section>
</div>
</div>
<script src="https://revealjs.com/js/reveal.js"></script>

<script>
// Full list of configuration options available here:
// https://github.com/hakimel/reveal.js#configuration
Reveal.initialize({
multiplex: {
    secret: '', // null if client
    id: '', // id, obtained from socket.io server
    url: '' // Location of socket.io server
},

// Optional libraries used to extend on reveal.js
dependencies: [
 { src: 'https://revealjs.com/plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } },
]
});
</script>
</body>
</html>
